{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1923ad47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Highly Scalable Data Pipelines with Prefects-16\n",
    "\n",
    "## Our Journey in Leveraging Prefect & k8s to enable Resilient, Orchestrated Workflows\n",
    "\n",
    "### David Zucker\n",
    "### 2021-09-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb349697",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is our Team about ?\n",
    "\n",
    "- Provide to the business advance recommendation\n",
    "- Ensure quality of data\n",
    "- Data provider/aggregator for our platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47f17a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What was our evolution ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e0397",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## November 2019: First release\n",
    "\n",
    "**Pro**\n",
    "- Running on Kubernetes\n",
    "\n",
    "**Con**\n",
    "- Single big Pod, Hard to Kubernetes to find space to started\n",
    "- Took 5h to process the full model\n",
    "- Use CronJob to schedule the run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0df2a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## June 2020: First use of Prefect Core\n",
    "\n",
    "**Pro**\n",
    "- Running on Kubernetes\n",
    "- Use Dask for scale out\n",
    "- Took <1h to process the full model\n",
    "\n",
    "**Con**\n",
    "- Use CronJob to schedule the run\n",
    "- Hard to get inside about the platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a7be8b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## February 2021: Move to Prefect Server\n",
    "\n",
    "**Pro**\n",
    "- Running on Kubernetes\n",
    "- Use Dask for scale out\n",
    "- Took <1h to process the full model\n",
    "- Use Prefect Server to schedule and get inside about our runs\n",
    "\n",
    "**Con**\n",
    "- Still evolving/maturing platform with change from master version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a3d16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Let show how to evolve your Python code using Prefect Core\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29482b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our use case\n",
    "\n",
    "- Extract Daily market data at close of exchange\n",
    "- Need to run on Market Index daily\n",
    "- Need to load the data as fast as we can at close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00307324",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic Python implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d95359",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution explanation \n",
    "\n",
    "- Extract index composition from Stooq\n",
    "- Download daily market data for each symbols\n",
    "- Resample daily candles to weekly and monthly\n",
    "- Save all result to parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4630d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def index_to_stooq_id(index_name:str)-> str:\n",
    "    i_2_s = {\"DJI\": \"578\",\n",
    "            \"NDX\":\"580\",\n",
    "            \"HSI\":\"616\"}\n",
    "    return i_2_s[index_name]\n",
    "\n",
    "def get_index_composition(index_id: str) -> pd.DataFrame:\n",
    "    return pd.read_html(f\"https://stooq.com/t/?i={index_id}\", attrs = {\"id\": \"fth1\"})[0]\n",
    "\n",
    "def get_symbols(df_index_composition: pd.DataFrame) -> List[str]:\n",
    "    return [symbol for symbol in df_index_composition[\"Symbol\"]]\n",
    "\n",
    "def get_historical_data(symbol: str, time_frame: str=\"d\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(f\"https://stooq.com/q/d/l/?s={symbol}&i={time_frame}\", parse_dates=True)\n",
    "    df['Date'] =  pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f751f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def resample_candle(df_daily:pd.DataFrame, resampling: str = \"W\") -> pd.DataFrame:\n",
    "    agg_dict = {'Open': 'first',\n",
    "          'High': 'max',\n",
    "          'Low': 'min',\n",
    "          'Close': 'last',\n",
    "          'Volume': 'mean'}\n",
    "    df_with_index = df_daily.set_index(\"Date\")\n",
    "    return df_with_index.resample(resampling).agg(agg_dict).reset_index()\n",
    "\n",
    "def save_to_parquet(df: pd.DataFrame, path: str):\n",
    "    pathlib.Path(path).expanduser().parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b615bcd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "index_name = \"DJI\"\n",
    "root_market_data = \"~/git/prefect_presentation/market_data\"\n",
    "\n",
    "\n",
    "print(f\"=> Extract composition for {index_name}\")\n",
    "index_id = index_to_stooq_id(index_name)\n",
    "df_composition = get_index_composition(index_id)\n",
    "\n",
    "\n",
    "for symbol in get_symbols(df_composition)[:6]:\n",
    "    start = time.time()\n",
    "    print(f\"==> Extract market data for {symbol}\", end =\" \")\n",
    "    df_OHLC_daily = get_historical_data(symbol)\n",
    "    save_to_parquet(df_OHLC_daily, f\"{root_market_data}/{index_name}/{symbol}_d.parquet\")\n",
    "    print(\"Resample W.\", end =\" \")\n",
    "    df_OHLC_weekly = resample_candle(df_OHLC_daily, \"W\")\n",
    "    save_to_parquet(df_OHLC_weekly, f\"{root_market_data}/{index_name}/{symbol}_W.parquet\")\n",
    "    print(\"M\", end =\" \")\n",
    "    df_OHLC_monthly = resample_candle(df_OHLC_daily, \"M\")\n",
    "    save_to_parquet(df_OHLC_monthly, f\"{root_market_data}/{index_name}/{symbol}_M.parquet\")\n",
    "    end = time.time()\n",
    "    print(f\"took: {end - start:2.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888428a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Limitation\n",
    "\n",
    "- Linear execution\n",
    "- Hard scale out without code complexity (Threading or asyncio)\n",
    "- No failover/retry capability\n",
    "- Load of edge case to handle to be resilient\n",
    "- Depend on external solution to schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae86be1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Upgrading the code with Prefect Core\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db87e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Few components you need to know\n",
    "\n",
    "1. **Task**: Low level execution unit. Simple function decorated with the attribute ```@task```\n",
    "2. **Flow**: Container of tasks with their dependencies\n",
    "3. **Parameters**: Special task that allow to change input value of the flow at run time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623da53",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task\n",
    "\n",
    "``` python\n",
    "from prefect import task\n",
    "\n",
    "@task\n",
    "def plus_one(x):\n",
    "    return x + 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a614510",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task: Failover support\n",
    "\n",
    "- max_retries\n",
    "- retry_delay\n",
    "- timeout\n",
    "\n",
    "``` python\n",
    "from prefect import task\n",
    "from datetime import timedelta\n",
    "\n",
    "@task(max_retries=4, retry_delay=timedelta(seconds=10), timeout=timedelta(seconds=2))\n",
    "def plus_one(x):\n",
    "    return x + 1\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3c765",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task: Functional map\n",
    "\n",
    "- Map allow to iterate a list of element through a task.\n",
    "- Powerful to distribute work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a373a31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from prefect import task, Flow, unmapped\n",
    "from datetime import timedelta\n",
    "from typing import List\n",
    "\n",
    "@task\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "@task\n",
    "def elements() -> List[int]:\n",
    "     return [x for x in range(1,11)]\n",
    "    \n",
    "with Flow(\"sample\") as f:\n",
    "    ints = elements()\n",
    "    # Will iterate through all element and add the value 10\n",
    "    result_add = add.map(unmapped(10), ints)\n",
    "    \n",
    "flow_state = f.run()\n",
    "flow_state.result[result_add].result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92360a52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task Library\n",
    "\n",
    "- Set of share task supported by prefect\n",
    "- Wide variaty that allow simple integration\n",
    " \n",
    " ### Some example\n",
    "     - Shellscript\n",
    "     - KubernetesJob\n",
    "     - Lambda function\n",
    "     - Multiple database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3f27d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task Library\n",
    "\n",
    "![media/prefect_task_1.png](media/prefect_tasks_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582fa2c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task Library\n",
    "\n",
    "![media/prefect_task_2.png](media/prefect_tasks_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7f587",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Task Library\n",
    "\n",
    "![media/prefect_task_3.png](media/prefect_tasks_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953c5d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Flow\n",
    "\n",
    "- Container of task\n",
    "- Contain the DAG that will run\n",
    "- Abstract the What to run from the How to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97579943",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from prefect import task, Flow, Parameter, unmapped\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "@task\n",
    "def index_to_stooq_id(index_name:str)-> str:\n",
    "    i_2_s = {\"DJI\": \"578\",\n",
    "            \"NDX\":\"580\",\n",
    "            \"HSI\":\"616\"}\n",
    "    return i_2_s[index_name]\n",
    "\n",
    "@task(max_retries=4, retry_delay=timedelta(seconds=2), timeout=timedelta(seconds=4))\n",
    "def get_index_composition(index_id: str) -> pd.DataFrame:\n",
    "    return pd.read_html(f\"https://stooq.com/t/?i={index_id}\", attrs = {\"id\": \"fth1\"})[0]\n",
    "\n",
    "@task\n",
    "def get_symbols(df_index_composition: pd.DataFrame) -> List[str]:\n",
    "    return [symbol for symbol in df_index_composition[\"Symbol\"][:6]]\n",
    "\n",
    "@task(max_retries=4, retry_delay=timedelta(seconds=2), timeout=timedelta(seconds=6))\n",
    "def get_historical_data(symbol: str, time_frame: str=\"d\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(f\"https://stooq.com/q/d/l/?s={symbol}&i={time_frame}\", parse_dates=True)\n",
    "    df['Date'] =  pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d773bc0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@task\n",
    "def resample_candle(df_daily:pd.DataFrame, time_frame: str = \"W\") -> pd.DataFrame:\n",
    "    agg_dict = {'Open': 'first',\n",
    "          'High': 'max',\n",
    "          'Low': 'min',\n",
    "          'Close': 'last',\n",
    "          'Volume': 'mean'}\n",
    "    df_with_index = df_daily.set_index(\"Date\")\n",
    "    return df_with_index.resample(time_frame).agg(agg_dict).reset_index()\n",
    "\n",
    "@task\n",
    "def get_save_path(root:str, index_name: str, symbol:str, timeframe:str)-> str:\n",
    "    return f\"{root}/{index_name}/{symbol}_{timeframe}.parquet\"\n",
    "\n",
    "@task\n",
    "def save_to_parquet(df: pd.DataFrame, path: str):\n",
    "    pathlib.Path(path).expanduser().parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a33cb4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with Flow(\"extract_market_data\") as f:\n",
    "    # Define the flow input parameters\n",
    "    index_name = Parameter(\"index\", default=\"DJI\")\n",
    "    root_market_data = Parameter(\"root_folder\", \"~/git/prefect_presentation/market_data\")\n",
    "    \n",
    "    # Retrieve the symbols for the index\n",
    "    index_id = index_to_stooq_id(index_name)\n",
    "    df_composition = get_index_composition(index_id)\n",
    "    symbols = get_symbols(df_composition)\n",
    "    \n",
    "    # Download the market data for the index\n",
    "    df_OHLC_daily = get_historical_data.map(symbols)\n",
    "    daily_path = get_save_path.map(unmapped(root_market_data),unmapped(index_name), symbols, unmapped(\"d\") )\n",
    "    save_to_parquet.map(df_OHLC_daily, daily_path)\n",
    "    \n",
    "    # Resample the market data to Weekly\n",
    "    df_weekly = resample_candle.map(df_OHLC_daily, unmapped(\"W\"))\n",
    "    weekly_path = get_save_path.map(unmapped(root_market_data),unmapped(index_name), symbols, unmapped(\"W\") )\n",
    "    save_to_parquet.map(df_weekly, weekly_path)\n",
    "    \n",
    "    # Resample the market data to Monthly\n",
    "    df_monthly = resample_candle.map(df_OHLC_daily, unmapped(\"M\"))\n",
    "    monthly_path = get_save_path.map(unmapped(root_market_data),unmapped(index_name), symbols, unmapped(\"M\") )\n",
    "    save_to_parquet.map(df_monthly, monthly_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e861a39",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lets have a look at the workflow\n",
    "\n",
    "- Prefect view of the DAG\n",
    "- Show dependencies\n",
    "- Distinguish mapped and non mapped task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36389d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943be9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Time for a run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b906534",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "flow_state = f.run(parameters={\"index\": \"DJI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e7d91",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## DAG that prefect ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe02816",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f.visualize(flow_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059acfb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This look like sequential to me !!!!\n",
    "```\n",
    "[2021-09-13 17:25:56+0800] INFO - prefect.TaskRunner | Task 'get_historical_data': Starting task run...\n",
    "[2021-09-13 17:25:56+0800] INFO - prefect.TaskRunner | Task 'get_historical_data': Finished task run for task with final state: 'Mapped'\n",
    "[2021-09-13 17:25:56+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[0]': Starting task run...\n",
    "[2021-09-13 17:26:00+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[0]': Finished task run for task with final state: 'Success'\n",
    "[2021-09-13 17:26:00+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[1]': Starting task run...\n",
    "[2021-09-13 17:26:04+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[1]': Finished task run for task with final state: 'Success'\n",
    "[2021-09-13 17:26:05+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[2]': Starting task run...\n",
    "[2021-09-13 17:26:10+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[2]': Finished task run for task with final state: 'Success'\n",
    "[2021-09-13 17:26:10+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[3]': Starting task run...\n",
    "[2021-09-13 17:26:16+0800] INFO - prefect.TaskRunner | Task 'get_historical_data[3]': Finished task run for task with final state: 'Retrying'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac543cf4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prefect Modularity\n",
    "\n",
    "- **Executors**: Define how you want to run your workflow\n",
    "- **Storage**: Define the where the flow definition are stored.\n",
    "- **Result**: Define where task result are persisted\n",
    "- **Serialization**: Define how you want to stream your data\n",
    "- **State Handle**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2072e5c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Result\n",
    "\n",
    "- Abstract the result type (Local, S3, Azure Blob Storage...)\n",
    "- Allow you to define how we want to serialize the result\n",
    "- Dynamic path generation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb6592",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from prefect.engine.results import LocalResult\n",
    "from prefect.engine.serializers import PandasSerializer\n",
    "\n",
    "MARKET_RESULT = LocalResult(dir=\"~/market_data/\", serializer=PandasSerializer(file_type=\"parquet\"))\n",
    "TARGET_STOCK = \"stock/{today_nodash}/{symbol}.{time_frame}.parquet\"\n",
    "\n",
    "@task(checkpoint=True,\n",
    "      target=\"index/{today_nodash}/{index_name}.parquet\",\n",
    "      result=MARKET_RESULT)\n",
    "def get_index_composition(index_id: str, index_name: str) -> pd.DataFrame:\n",
    "    return pd.read_html(f\"https://stooq.com/t/?i={index_id}\", attrs = {\"id\": \"fth1\"})[0]\n",
    "\n",
    "@task(checkpoint=True,\n",
    "      target=TARGET_STOCK,\n",
    "      result=MARKET_RESULT)\n",
    "def get_historical_data(symbol: str, time_frame: str=\"d\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(f\"https://stooq.com/q/d/l/?s={symbol}&i={time_frame}\", parse_dates=True)\n",
    "    df['Date'] =  pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51870da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@task(checkpoint=True,\n",
    "      target=TARGET_STOCK,\n",
    "      result=MARKET_RESULT)\n",
    "def resample_candle(df_daily:pd.DataFrame, symbol:str, time_frame: str = \"W\") -> pd.DataFrame:\n",
    "    agg_dict = {'Open': 'first',\n",
    "          'High': 'max',\n",
    "          'Low': 'min',\n",
    "          'Close': 'last',\n",
    "          'Volume': 'mean'}\n",
    "    df_with_index = df_daily.set_index(\"Date\")\n",
    "    return df_with_index.resample(time_frame).agg(agg_dict).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dcc0c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with Flow(\"extract_market_data_with_result\") as f_with_result:\n",
    "    # Define the flow input parameters\n",
    "    index_name = Parameter(\"index\", default=\"DJI\")\n",
    "    root_market_data = Parameter(\"root_folder\", \"~/git/prefect_presentation/market_data\")\n",
    "    \n",
    "    # Retrieve the symbols for the index\n",
    "    index_id = index_to_stooq_id(index_name)\n",
    "    df_composition = get_index_composition(index_id, index_name)\n",
    "    symbols = get_symbols(df_composition)\n",
    "\n",
    "    df_OHLC_daily = get_historical_data.map(symbols, unmapped(\"d\"))\n",
    "    df_weekly = resample_candle.map(df_OHLC_daily, symbols, unmapped(\"W\"))\n",
    "    df_monthly = resample_candle.map(df_OHLC_daily, symbols, unmapped(\"M\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfe260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prefect\n",
    "prefect.context.config.flows.checkpointing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_with_result.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02f462",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Executors\n",
    "\n",
    "Responsible for actually executing the tasks\n",
    "\n",
    "- **LocalExecutor**: Single threaded executor in memory\n",
    "- **LocalDaskExecutor**: Use local dask executor to run in multi-threaded\n",
    "- **DaskExecutor**: Use Dask distributed to sent task to remote worker\n",
    "\n",
    "#### Dask: Dask is an open source library for parallel computing written in Python.[\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de4dc3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running with LocalDaskExecutor\n",
    "\n",
    "- Initialize a LocalDaskExecutor\n",
    "- Set the executor in the run function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d49cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from prefect.executors import LocalDaskExecutor \n",
    "from flows.extract_market_data import flow_market\n",
    "executor = LocalDaskExecutor(scheduler=\"threads\", nb_threads=\"8\")\n",
    "flow_market.run(executor=executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7cff8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Running with DaskExecutor\n",
    "\n",
    "- Advance executor to dask\n",
    "- Require an external dask cluster running\n",
    "- Allow to scale out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90eb6bb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from prefect.executors import DaskExecutor \n",
    "from flows.dask_cluster import DaskCluster\n",
    "from flows.extract_market_data import flow_market\n",
    "from prefect.utilities.logging import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "with DaskCluster(logger) as cluster:\n",
    "    executor = DaskExecutor(address=cluster.scheduler_address)\n",
    "    flow_market.run(executor=executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4ec28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prefect Server / Prefect Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28dcd26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Prefect Server\n",
    "\n",
    "- Allow orchestration and monitoring of flow\n",
    "- Complete UI for flows and jobs\n",
    "- Control API using GraphQL\n",
    "- Automatic and asynchronous scheduling and alerting\n",
    "- Hybrid mode to make Prefect a reliable option for enterprise ( code and data remain on-prem )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11cb12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Prefect Server vs Prefect Cloud\n",
    "\n",
    "|  | Prefect Server      | Prefect Cloud |\n",
    "| ---- | ----------- | ----------- |\n",
    "| License | Open Source (Prefect Community License) | Commecial |\n",
    "| Authentication | None (Can use reverse Proxy | SSO integreation |\n",
    "| Permissioning | None | Advance with Role |\n",
    "| Secret managemnt | None | Managed |\n",
    "| KV Storage | None | Managed |\n",
    "| Flow Concurency | None | Ensure nb flow run |\n",
    "| Alerting | Basic | Advance capability |\n",
    "| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db918f6f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Architecture\n",
    "\n",
    "![architecture](./media/prefect_architecture_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f38678",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Start Prefect Sever localy\n",
    "\n",
    "- Prefect suport local server using Docker\n",
    "- Perfect for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d156ec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!./start_prefect_server.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62059b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Prefect Server overview\n",
    "\n",
    "[Prefect Server url http://localhost:8080](http://localhost:8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7a790",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Register job\n",
    "\n",
    "- Register the Job to Prefect Server/Cloud\n",
    "- Save the Job metadata to the Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807732fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!./register_flow.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d28dcf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!./start_server.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c95fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Start Prefect agent and run job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5058bc3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!./stop_prefect_agent_dask.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bf1f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let run our job and check Dask\n",
    "\n",
    "[Dask Scheduler](http://localhost:8787/status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963e81a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!./stop_prefect_agent_dask.sh\n",
    "!./stop_prefect_server.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75348290",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is our platform today ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bd124",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our stack\n",
    "\n",
    "- **Prefect Server**: Running on our own Kubernetes instance\n",
    "- **Dask Cluster**: Everytime up using dask cluster\n",
    "    - Running on Kubernetes\n",
    "    - Leverage HPA using Dask custom metrics *dask_scheduler_desired_workers*\n",
    "- **S3 Storage**: Using our internal instance of S3 for all our machine learning processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8262ee2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Question ?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
